---
layout: post
title: 算法复杂度分析(上)
date: 2020-02-19 23:03
updated: 2020-02-20 00:25
categories: 算法
tags: 
    - 大O
    - 算法
    - 时间复杂度
    - 空间复杂度
urlname: 24
mathjax: true
comment: true
---

刷题的时候经常都会看到 O(n<sup>2</sup>) 之类的公式用来表示某个算法的复杂度，我也只能大概的判断大小。最近正在系统的学习数据结构，这里也记录以下自己的思路，同时能帮助到其他朋友理解到，就更好了。

<!-- more -->

## 为什么需要复杂度分析

在写代码的时候，我总是会有意识的想要提升运行效率，但是我在写完了一段代码后我也不知道它的速度是快还是慢。我甚至会在满足一些自己所谓的高效率，而花费太多不必要的时间。

通过对空间、时间复杂度的分析，可以让我写代码时更佳自信。

## 大 O 复杂度表示法

先上代码

```java
public static int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i <= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
```

一个简单的 计算数列和 的代码，也就是 `1, 2, 3, ... ， n-1, n` 所有数字的和。

虽然计算机运行代码的时间，会比想象中的难以计算因为每一行代码都是不同的，还会有很多不确定的情况。但是在计算复杂度时，都会大致将其看作一行代码，花了一个单位时间。

所以在这段代码中，L2-3 分别运行了一次，L4-5 分别运行了 n 次。那么我将这个代码的运行时间大概估计为 $2n+2$ 次，同时得出了一个结论，**所有代码的执行时间 T(n) 与每行代码的执行次数成正比。**

再看一段代码

```java
public static int cal(int n) {
   int sum = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1;
     for (; j <= n; ++j) {
       sum = sum +  i * j;
     }
   }
   return sum;
 }
```

在这一段代码中，L2-4 一共运行了 3 次（L1 初始化就不计了），L5 和 L6 都运行了 n 次，那么一共需要 $2n$ 次。L7 和 L8 都运行了 $n^2$ 次，那么一共运行了 $2n^2$ 次。如果把运行一次的时间设为 RunTime ，这段代码一共运行的时间 T(n) 为。

$$ T(n)=(2n^2+2n+3)*RunTime $$

通过对这两段代码的分析，我们可以得到一个非常重要的规律，即，**所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比**。

我们可以把这个规律总结成一个规律，也就是

$$ T(n)=O(f(n)) $$

| 符号 | 含义 |
| -- | -- |
| T(n) | 代码执行的时间 |
| n | 数据的规模大小 |
| f(n) | 每行代码执行的次数总和 |
| O | 代码的执行时间 T(n) 与 f(n) 表达式成正比 |

第一段代码的 $T(n)=O(2n+2)$ 和 第二段代码的 $T(n)=O(2n^2+2n+3)$ 也就是**大 O 时间复杂度表示法**。

> 大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示**代码执行时间随数据规模增长的变化趋势**，所以，也叫作**渐进时间复杂度**（asymptotic time complexity），简称**时间复杂度**。

当 n 很大时，你可以把它想象成 10000、100000。而公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了，如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为

$$ T(n) = O(n) $$

$$ T(n) = O(n^2) $$

## 时间复杂度分析

在进行时间复杂度分析时，可以使用这三个比较使用的方法。

### 只关注循环执行次数最多的一段代码

我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了。

还是第一段代码为例

```java
public static int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i <= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
```

因为在这段代码中，L2-3 都是常量级的执行时间，与 n 的数据大小无关，所以在我们进行时间复杂度分析时可忽略不计。而循环次数最多的 L4-5 才是我们需要关系的。在前面分析的时候也说了，它被执行了 n 次，所以时间复杂程度也就是 $O(n)$ 。

### 加法法则：总复杂度等于量级最大的那段代码的复杂度

```java
public static int cal(int n) {
   int sum_1 = 0;
   int p = 1;
   for (; p < 100; ++p) {
     sum_1 = sum_1 + p;
   }

   int sum_2 = 0;
   int q = 1;
   for (; q < n; ++q) {
     sum_2 = sum_2 + q;
   }
 
   int sum_3 = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1; 
     for (; j <= n; ++j) {
       sum_3 = sum_3 +  i * j;
     }
   }
 
   return sum_1 + sum_2 + sum_3;
 }
 ```

 不难看出来第一段循环它的运行次数是固定的 100 次，所以是一个常量的执行时间，这是与 n 无关的。

 第二段代码的循环次数是根据输入的 n 来决定的，所以它的时间复杂度为 $O(n)$ 。

 第三段代码也就是在第二段的基础上，又加了一次，也就是 $O(n^2)$ 。

 我们在计算的时候，只选取其中时间复杂度最大的一个。所以这段代码的时间复杂度为 $O(n^2)$ 。

 也就是说：总的时间复杂度就等于量级最大的那段代码的时间复杂度

 ### 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

 ```java
public static int cal(int n) {
   int ret = 0; 
   int i = 1;
   for (; i < n; ++i) {
     ret = ret + f(i);
   } 
 } 
 
 int f(int n) {
  int sum = 0;
  int i = 1;
  for (; i < n; ++i) {
    sum = sum + i;
  } 
  return sum;
 }
 ```

我们单独看 cal() 函数。假设 f() 只是一个普通的操作，那第 4～6 行的时间复杂度就是，$T1(n) = O(n)$。但 f() 函数本身不是一个简单的操作，它的时间复杂度是 $T2(n) = O(n)$，所以，整个 cal() 函数的时间复杂度就是，$T(n) = T1(n) * T2(n) = O(n*n) = O(n2)$。

## 几种常见时间复杂度实例分析

虽然代码千差万别，但是常见的复杂度量级也就只有几个。大致可以分为两类。

多项式量级：

- 常量阶 $ O(1) $
- 对数阶 $ O(logn) $
- 线性阶 $ O(n) $
- 线性对数阶 $ O(nlogn) $
- 平方阶 $O(n^2)$、立方阶 $O(n^3)$ ... K次方阶 $O(n^k)$

非多项式量级：

- 指数阶 $O(2^n)$
- 阶乘阶 $O(n!)$

我们把时间复杂度为非多项式量级的算法问题叫作 NP（Non-Deterministic Polynomial，非确定多项式）问题。

当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。因此，关于 NP 时间复杂度我就不展开讲了。我们主要来看几种常见的**多项式时间复杂度**。

### O(1)

需要注意的是，$O(1)$ 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。比如这段代码，即使有 3 行，它的时间复杂度也是 $O(1)$，而不是 $O(3)$。

```java
 int i = 8;
 int j = 6;
 int sum = i + j;
 ```

可以说，只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作$O(1)$。或者说，**一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是 $O(1)$**。

### O(logn)、O(nlogn)

对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。看代码。

```java
 i=1;
 while (i <= n)  {
   i = i * 2;
 }
```

根据我们前面讲的复杂度分析方法，第三行代码是循环执行次数最多的。所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。

从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以 2。当大于 n 时，循环结束。还记得我们高中学过的等比数列吗？实际上，变量 i 的取值就是一个等比数列。如果我把它一个一个列出来，就应该是这个样子的：

$$ 2^0, 2^1, 2^2, ... 2^{x-1}, 2^x = n $$

每一个数都是前一个数再乘一个 2。

所以，我们只要知道 x 值是多少，就知道这行代码执行的次数了。通过 $2^x=n$ 求解 x 就是 $x=log_2n$，所以，这段代码的时间复杂度就是

$$ O(log_2n) $$

再看一段代码

```java
 i=1;
 while (i <= n)  {
   i = i * 3;
 }
```

根据我刚刚的思路，很简单就能看出来，这段代码的时间复杂度为 $O(log_3n)$。

实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 $O(logn)$。为什么呢？

我们知道，对数之间是可以互相转换的，$log_3n$ 可以进行以下转换。以下所有变换均使用了如下的换底公式。

$$ log_bN = \frac{log_aN}{log_ab} $$

下面开始进行互换，首先设 a 为 2 将所有数换为以 2 为底的。将含有 n 的分母移出来。再使用换底公式将 $log_23$ 换为以 3 为底的。又因为分母的 $log_33=1$ 所以我们换底就成功拉。

$$log_3n $= \frac{log_2n}{log_23}\\
 $= \frac{1}{log_23} \cdot log_2n\\
 $= \frac{1}{\frac{log_33}{log_32}}\cdot log_2n\\
 $= \frac{log_32}{log_33}\cdot log_2n\\
 $= \frac{log_32}{1}\cdot log_2n\\
 $= log_32\cdot log_2n$$

因为 $log_3n$ 等于 $log_32 * log_2n$，所以 $O(log_3n) = O(C*log_2n)$，其中 $C=log_32$ 是一个常量。基于我们前面的一个理论：**在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))**。所以，$O(log_2n)$ 就等于 $O(log_3n)$。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为 $O(logn)$。

如果你理解了我前面讲的 $O(logn)$，那 $O(nlogn)$ 就很容易理解了。还记得我们刚讲的乘法法则吗？如果一段代码的时间复杂度是 $O(logn)$，我们循环执行 n 遍，时间复杂度就是 $O(nlogn)$ 了。而且，$O(nlogn)$ 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 $O(nlogn)$。

### O(m+n)、O(m*n)

我们再来讲一种跟前面都不一样的时间复杂度，代码的复杂度**由两个数据的规模**来决定。

```java
public static int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }

  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }

  return sum_1 + sum_2;
}
```

从代码中可以看出，m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 $O(m+n)$。

针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：$T1(m) + T2(n) = O(f(m) + g(n))$。但是乘法法则继续有效：$T1(m)*T2(n) = O(f(m) * f(n))$。

## 空间复杂度分析

时间复杂度的全称是**渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系**。类比一下，空间复杂度全称就是**渐进空间复杂度**（asymptotic space complexity），**表示算法的存储空间与数据规模之间的增长关系**。

先看一段有点傻的代码

```java
public static void print(int n) {
  int i = 0;
  int[] a = new int[n];
  for (i; i <n; ++i) {
    a[i] = i * i;
  }

  for (i = n-1; i >= 0; --i) {
    print out a[i]
  }
}
```

跟时间复杂度分析一样，我们可以看到，第 2 行代码中，我们申请了一个空间存储变量 i，但是它是常量阶的，跟数据规模 n 没有关系，所以我们可以忽略。第 3 行申请了一个大小为 n 的 int 类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 O(n)。

我们常见的空间复杂度就是 $O(1)$、$O(n)$、$O(n2)$，像 $O(logn)$、$O(nlogn)$ 这样的对数阶复杂度平时都用不到。而且，空间复杂度分析比时间复杂度分析要简单很多。所以，对于空间复杂度，这样就够了。

## 小结

复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系，可以粗略地表示，越高阶复杂度的算法，执行效率越低。常见的复杂度并不多，从低阶到高阶有：$O(1)$、$O(logn)$、$O(n)$、$O(nlogn)$、$O(n2)$。